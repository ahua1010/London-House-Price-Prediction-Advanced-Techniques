{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Score 185091\n",
    "\n",
    "MAE: 109640.8983, RMSE: 538318.4967, R²: 0.8215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改 baseline 後還沒跑出結果\n",
    "- 使用TimeSeriesSplit，專門用於時間序列資料的交叉驗證方法，它的設計目的是為了模擬「未來不能影響過去」的情況，防止資料洩漏（data leakage）\n",
    "- 新增價格/面積等「密度型衍生特徵」\n",
    "- 處理稀有類別 + 平滑 Target Encoding\n",
    "- 用 LightGBM 作為 HybridModel 的機器學習部分，並用 Optuna 自動搜尋最佳超參數\n",
    "- Clip 房價 + Winsorize 特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:00:21.704201Z",
     "iopub.status.busy": "2025-06-19T11:00:21.703537Z",
     "iopub.status.idle": "2025-06-19T11:00:21.761597Z",
     "shell.execute_reply": "2025-06-19T11:00:21.760978Z",
     "shell.execute_reply.started": "2025-06-19T11:00:21.704179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "倫敦房價預測 - 混合模型（趨勢分析 + 機器學習）\n",
    "使用時間序列特徵結合機器學習進行房價預測\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV,TimeSeriesSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "def objective(trial, X, y, trend_cols, machine_cols, all_columns):\n",
    "    params = {\n",
    "        \"device\": \"gpu\", \n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 6000, step=500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    # ➡ 將 Encoder 與 HybridModel 串成管線\n",
    "    model = Pipeline([\n",
    "        ('Encoder', CustomEncoder()),\n",
    "        ('Model', HybridModel(\n",
    "            trend_model=Ridge(alpha=0.1),\n",
    "            machine_model=LGBMRegressor(**params),\n",
    "            trend_cols=trend_cols,\n",
    "            machine_cols=machine_cols,\n",
    "            all_columns=all_columns\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = cross_val_score(model, X, y,\n",
    "                            cv=tscv,\n",
    "                            scoring='neg_mean_absolute_error',\n",
    "                            error_score='raise')   # 方便除錯\n",
    "    return -score.mean()\n",
    "\n",
    "def create_time_features(data_list):\n",
    "    \"\"\"創建時間相關特徵\"\"\"\n",
    "    print(\"創建時間特徵...\")\n",
    "    for data in data_list:\n",
    "        # 創建時間索引\n",
    "        data['time'] = pd.to_datetime(dict(\n",
    "            year=data['sale_year'], \n",
    "            month=data['sale_month'], \n",
    "            day=15\n",
    "        ))\n",
    "        data['time'] = data['time'].dt.to_period('M')\n",
    "        \n",
    "        # 創建數值型時間特徵\n",
    "        data['time_numeric'] = (\n",
    "            (data['time'].dt.to_timestamp() - data['time'].min().to_timestamp()) / \n",
    "            np.timedelta64(1, 'D')\n",
    "        )\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "def preprocess_address_features(data_list):\n",
    "    \"\"\"處理地址相關特徵\"\"\"\n",
    "    print(\"處理地址特徵...\")\n",
    "    for data in data_list:\n",
    "        # 提取街道資訊\n",
    "        data['street'] = data['fullAddress'].apply(\n",
    "            lambda address: ' '.join(address.split(',')[-3].split(' ')[-2:])\n",
    "        )\n",
    "        \n",
    "        # 處理郵遞區號\n",
    "        data['postcode'] = data['postcode'].apply(\n",
    "            lambda postcode: postcode.split(' ')[1]\n",
    "        )\n",
    "        \n",
    "        # 移除國家欄位（所有資料都是同一個國家）\n",
    "        data.drop('country', axis=1, inplace=True)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "def impute_missing_values_with_strategy(data_list, column_name, strategy='most_frequent'):\n",
    "    \"\"\"使用指定策略填補缺失值\"\"\"\n",
    "    print(f\"填補 {column_name} 的缺失值（策略：{strategy}）...\")\n",
    "    \n",
    "    # 從訓練資料學習填補策略\n",
    "    train_data = data_list[0]  # 第一個是訓練資料\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    imputer.fit(train_data[[column_name]])\n",
    "    \n",
    "    # 對所有資料集應用填補\n",
    "    for data in data_list:\n",
    "        data[column_name] = imputer.transform(data[[column_name]]).ravel()\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "def impute_with_regression(data_list, target_column, feature_column):\n",
    "    \"\"\"使用回歸模型填補缺失值\"\"\"\n",
    "    print(f\"使用 {feature_column} 預測填補 {target_column} 的缺失值...\")\n",
    "    \n",
    "    train_data = data_list[0]\n",
    "    test_data = data_list[1]\n",
    "    \n",
    "    # 準備完整的訓練資料\n",
    "    complete_train_data = train_data.dropna(subset=[target_column, feature_column])\n",
    "    X_train = complete_train_data[[feature_column]]\n",
    "    y_train = complete_train_data[target_column]\n",
    "    \n",
    "    # 訓練回歸模型\n",
    "    regression_model = Ridge()\n",
    "    regression_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 填補訓練集的缺失值\n",
    "    missing_train_mask = train_data[target_column].isna()\n",
    "    if missing_train_mask.any():\n",
    "        missing_train_features = train_data.loc[missing_train_mask, [feature_column]]\n",
    "        train_data.loc[missing_train_mask, target_column] = regression_model.predict(missing_train_features)\n",
    "    \n",
    "    # 填補測試集的缺失值\n",
    "    missing_test_mask = test_data[target_column].isna()\n",
    "    if missing_test_mask.any():\n",
    "        missing_test_features = test_data.loc[missing_test_mask, [feature_column]]\n",
    "        test_data.loc[missing_test_mask, target_column] = regression_model.predict(missing_test_features)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def handle_missing_values(data_list):\n",
    "    \"\"\"處理所有缺失值\"\"\"\n",
    "    print(\"開始處理缺失值...\")\n",
    "    \n",
    "    # 使用最頻繁值填補面積\n",
    "    data_list = impute_missing_values_with_strategy(data_list, 'floorAreaSqM')\n",
    "    \n",
    "    # 使用面積預測浴室數量\n",
    "    data_list = impute_with_regression(data_list, 'bathrooms', 'floorAreaSqM')\n",
    "    \n",
    "    # 使用面積預測臥室數量\n",
    "    data_list = impute_with_regression(data_list, 'bedrooms', 'floorAreaSqM')\n",
    "    \n",
    "    # 使用最頻繁值填補其他類別特徵\n",
    "    categorical_columns = ['livingRooms', 'tenure', 'propertyType', 'currentEnergyRating']\n",
    "    for column in categorical_columns:\n",
    "        data_list = impute_missing_values_with_strategy(data_list, column)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "def create_time_series_features(train_data, test_data):\n",
    "    \"\"\"創建時間序列特徵\"\"\"\n",
    "    print(\"創建時間序列特徵...\")\n",
    "    \n",
    "    # 創建確定性過程（趨勢、季節性、週期性）\n",
    "    deterministic_process = DeterministicProcess(\n",
    "        index=train_data.index.unique(),\n",
    "        constant=True,        # 常數項\n",
    "        seasonal=True,        # 季節性\n",
    "        order=12,            # 趨勢階數\n",
    "        drop=True,           # 移除共線性\n",
    "        additional_terms=[CalendarFourier(freq=\"QE\", order=4)],  # 季度傅立葉項\n",
    "    )\n",
    "    \n",
    "    # 為訓練資料添加時間序列特徵\n",
    "    time_features_train = deterministic_process.in_sample()\n",
    "    train_data = train_data.join(time_features_train, how='left')\n",
    "    \n",
    "    # 計算預測相關參數\n",
    "    forecast_origin = train_data.index.max()\n",
    "    forecast_lead = test_data.index.min() - forecast_origin\n",
    "    forecast_horizon = test_data.index.max() - test_data.index.min()\n",
    "    \n",
    "    print(f\"預測起點: {forecast_origin}\")\n",
    "    print(f\"領先時間: {forecast_lead.n} 個月\")\n",
    "    print(f\"預測範圍: {forecast_horizon.n} 個月\")\n",
    "    \n",
    "    # 為測試資料添加時間序列特徵\n",
    "    time_features_test = deterministic_process.out_of_sample(\n",
    "        steps=forecast_horizon.n + forecast_lead.n\n",
    "    )\n",
    "    test_data = test_data.join(time_features_test, how='left')\n",
    "    test_data.index.name = 'time'\n",
    "    \n",
    "    return train_data, test_data, time_features_train.columns.tolist()\n",
    "\n",
    "\n",
    "def create_additional_features(data_list):\n",
    "    \"\"\"創建額外的特徵\"\"\"\n",
    "    print(\"創建額外特徵...\")\n",
    "    \n",
    "    for data in data_list:\n",
    "        # 總房間數 = 臥室 + 起居室\n",
    "        data['rooms'] = data['bedrooms'] + data['livingRooms']\n",
    "        # 總房間數 = 臥室 + 起居室\n",
    "        data['rooms'] = data['bedrooms'] + data['livingRooms']\n",
    "        \n",
    "        # 衍生密度特徵\n",
    "        # data['price_per_sqm'] = data['price'] / np.maximum(data['floorAreaSqM'], 1)\n",
    "        data['rooms_per_bedroom'] = data['rooms'] / np.maximum(data['bedrooms'], 1)\n",
    "        data['bath_per_room'] = data['bathrooms'] / np.maximum(data['rooms'], 1)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "class CustomEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.target_mean_encoders = {}\n",
    "        self.fallback_values = {}\n",
    "        self.bin_encoders = {}\n",
    "        self.ordinal_encoders = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['price'] = y\n",
    "        \n",
    "        # 舊版的簡單目標編碼 (不處理稀有值，不平滑)\n",
    "        target_encoding_features = ['street', 'postcode', 'outcode', 'tenure', 'propertyType']\n",
    "        for feature in target_encoding_features:\n",
    "            self.target_mean_encoders[feature] = X_copy.groupby(feature)['price'].mean()\n",
    "            self.fallback_values[feature] = self.target_mean_encoders[feature].mean()\n",
    "        \n",
    "        # 舊版的分箱和順序編碼邏輯\n",
    "        latitude_bins = pd.cut(X_copy['latitude'], bins=10, retbins=True)[1]\n",
    "        self.bin_encoders['latitudeBins'] = latitude_bins\n",
    "        \n",
    "        longitude_bins = pd.cut(X_copy['longitude'], bins=10, retbins=True)[1]\n",
    "        self.bin_encoders['longitudeBins'] = longitude_bins\n",
    "        \n",
    "        energy_rating_order = [['G', 'F', 'E', 'D', 'C', 'B', 'A']]\n",
    "        # 處理訓練集中可能存在的未知評級\n",
    "        present_ratings = X_copy['currentEnergyRating'].unique()\n",
    "        for r in present_ratings:\n",
    "            if r not in energy_rating_order[0]:\n",
    "                energy_rating_order[0].append(r)\n",
    "\n",
    "        self.ordinal_encoders['currentEnergyRating'] = OrdinalEncoder(\n",
    "            categories=energy_rating_order,\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-1\n",
    "        ).fit(X_copy[['currentEnergyRating']])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # 應用目標編碼\n",
    "        target_encoding_features = ['street', 'postcode', 'outcode', 'tenure', 'propertyType']\n",
    "        for feature in target_encoding_features:\n",
    "            X_transformed[feature] = X_transformed[feature].map(self.target_mean_encoders[feature])\n",
    "            X_transformed[feature] = X_transformed[feature].fillna(self.fallback_values[feature])\n",
    "        \n",
    "        # 緯度和經度分箱 (使用 labels=False，更穩健)\n",
    "        X_transformed['latitudeBins'] = pd.cut(X_transformed['latitude'], bins=self.bin_encoders['latitudeBins'], include_lowest=True, right=True, labels=False)\n",
    "        X_transformed['longitudeBins'] = pd.cut(X_transformed['longitude'], bins=self.bin_encoders['longitudeBins'], include_lowest=True, right=True, labels=False)\n",
    "        \n",
    "        # 能源評級順序編碼\n",
    "        X_transformed['currentEnergyRating'] = self.ordinal_encoders['currentEnergyRating'].transform(\n",
    "            X_transformed[['currentEnergyRating']]\n",
    "        )\n",
    "        \n",
    "        return X_transformed\n",
    "\n",
    "class HybridModel(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    混合模型：結合趨勢模型和機器學習模型\n",
    "    - 趨勢模型：處理時間序列特徵\n",
    "    - 機器學習模型：處理殘差和其他特徵\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trend_model, machine_model, trend_cols, machine_cols, all_columns):\n",
    "        self.trend_model = trend_model\n",
    "        self.machine_model = machine_model\n",
    "        self.trend_cols = trend_cols\n",
    "        self.machine_cols = machine_cols\n",
    "        self.all_columns = all_columns\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"訓練混合模型\"\"\"\n",
    "        # 對目標變量進行對數轉換以穩定方差\n",
    "        y_log = np.log1p(y)\n",
    "        \n",
    "        # 確保輸入是 DataFrame 格式\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.all_columns)\n",
    "        \n",
    "        # 分離趨勢特徵和機器學習特徵\n",
    "        trend_features = X[self.trend_cols]\n",
    "        machine_features = X[self.machine_cols]\n",
    "        \n",
    "        # 1. 訓練趨勢模型\n",
    "        self.trend_model.fit(trend_features, y_log)\n",
    "        \n",
    "        # 2. 計算趨勢預測的殘差\n",
    "        trend_predictions = self.trend_model.predict(trend_features)\n",
    "        residual = y_log - trend_predictions\n",
    "        \n",
    "        # 3. 用機器學習模型學習殘差\n",
    "        self.machine_model.fit(machine_features, residual)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"進行預測\"\"\"\n",
    "        # 確保輸入是 DataFrame 格式\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.all_columns)\n",
    "        \n",
    "        # 分離特徵\n",
    "        trend_features = X[self.trend_cols]\n",
    "        machine_features = X[self.machine_cols]\n",
    "        \n",
    "        # 獲取趨勢預測和機器學習預測\n",
    "        trend_predictions = self.trend_model.predict(trend_features)\n",
    "        machine_predictions = self.machine_model.predict(machine_features)\n",
    "        \n",
    "        # 組合預測結果並反向對數轉換\n",
    "        combined_predictions = trend_predictions + machine_predictions\n",
    "        return np.expm1(combined_predictions)\n",
    "\n",
    "\n",
    "def prepare_features(train_data, test_data, time_series_features):\n",
    "    \"\"\"準備特徵集合\"\"\"\n",
    "    print(\"準備特徵集合...\")\n",
    "    \n",
    "    # 時間序列特徵（用於趨勢模型）\n",
    "    trend_features = time_series_features\n",
    "    \n",
    "    # 機器學習特徵（用於殘差模型）\n",
    "    machine_learning_features = [\n",
    "        'street', 'postcode', 'outcode', 'latitudeBins', 'longitudeBins',\n",
    "        'bathrooms', 'bedrooms', 'rooms', 'floorAreaSqM', 'livingRooms',\n",
    "        'tenure', 'propertyType', 'currentEnergyRating', 'rooms_per_bedroom', 'bath_per_room'\n",
    "    ]\n",
    "    \n",
    "    # 準備訓練特徵和目標\n",
    "    X_train = train_data.drop('price', axis=1)\n",
    "    y_train = train_data['price']\n",
    "    \n",
    "    # 標準化時間序列特徵\n",
    "    scaler = StandardScaler()\n",
    "    X_train[trend_features] = scaler.fit_transform(X_train[trend_features])\n",
    "    test_data[trend_features] = scaler.transform(test_data[trend_features])\n",
    "    \n",
    "    return X_train, y_train, trend_features, machine_learning_features\n",
    "\n",
    "\n",
    "def create_and_tune_model(X_train, y_train, trend_features, machine_learning_features):\n",
    "    \"\"\"創建並調優模型\"\"\"\n",
    "    print(\"創建混合模型並進行超參數調優...\")\n",
    "    \n",
    "    # 定義模型管道\n",
    "    model_pipeline = {\n",
    "        'HybridModel': Pipeline([\n",
    "            ('Encoder', CustomEncoder()),\n",
    "            ('Model', HybridModel(\n",
    "                trend_model=Ridge(),\n",
    "                machine_model=XGBRegressor(),\n",
    "                trend_cols=trend_features,\n",
    "                machine_cols=machine_learning_features,\n",
    "                all_columns=X_train.columns\n",
    "            ))\n",
    "        ]),\n",
    "    }\n",
    "    \n",
    "    # 定義超參數搜索空間\n",
    "    hyperparameter_grid = {\n",
    "        'HybridModel': {\n",
    "            'Model__trend_model__alpha': [0.01, 0.1],\n",
    "            'Model__machine_model__n_estimators': [300,600],\n",
    "            'Model__machine_model__max_depth': [4,6,8],\n",
    "            'Model__machine_model__learning_rate': [0.01, 0.005, 0.1],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 進行網格搜索\n",
    "    best_models = {}\n",
    "    for model_name, pipeline in model_pipeline.items():\n",
    "        print(f\"調優 {model_name}...\")\n",
    "        cv = TimeSeriesSplit(n_splits=5)\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, \n",
    "            hyperparameter_grid[model_name], \n",
    "            cv=cv, \n",
    "            scoring='neg_mean_absolute_error', \n",
    "            n_jobs=-1, \n",
    "            verbose=2, \n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"{model_name} 最佳參數: {grid_search.best_params_}\")\n",
    "        print(f\"{model_name} 最佳 MAE: {-grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "def create_and_tune_model_with_gridsearch(X_train, y_train, trend_features, machine_learning_features):\n",
    "    \"\"\"\n",
    "    創建混合模型，並使用 GridSearchCV 進行超參數調優。\n",
    "    - 使用 XGBRegressor 作為機器學習模型。\n",
    "    - 使用 TimeSeriesSplit 進行交叉驗證。\n",
    "    \"\"\"\n",
    "    print(\"創建混合模型並使用 GridSearchCV 進行超參數調優...\")\n",
    "\n",
    "    # 1. 定義模型管道，使用 XGBRegressor\n",
    "    # 這裡我們將機器學習模型換成了 XGBRegressor\n",
    "    model_pipeline = Pipeline([\n",
    "        ('Encoder', CustomEncoder()),\n",
    "        ('Model', HybridModel(\n",
    "            trend_model=Ridge(),\n",
    "            machine_model=XGBRegressor(random_state=42, eval_metric='mae'), # 使用 XGBoost\n",
    "            trend_cols=trend_features,\n",
    "            machine_cols=machine_learning_features,\n",
    "            all_columns=X_train.columns\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # 2. 定義與舊版 hybrid-model-trend-ml.py 相似的超參數搜索空間\n",
    "    hyperparameter_grid = {\n",
    "        'Model__trend_model__alpha': [0.01, 0.1],\n",
    "        'Model__machine_model__n_estimators': [500],\n",
    "        'Model__machine_model__max_depth': [9],\n",
    "        'Model__machine_model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    }\n",
    "\n",
    "    # 3. 進行網格搜索，但保留新版中正確的 TimeSeriesSplit\n",
    "    print(\"開始 GridSearchCV 調優...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search = GridSearchCV(\n",
    "        model_pipeline,\n",
    "        hyperparameter_grid,\n",
    "        cv=tscv,  # <-- 關鍵！我們保留了正確的時間序列交叉驗證方法\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"GridSearchCV 最佳參數: {grid_search.best_params_}\")\n",
    "    print(f\"GridSearchCV 最佳 MAE (CV): {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # 4. 返回訓練好的最佳模型\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def create_ensemble_model(best_models, X_train, y_train):\n",
    "    \"\"\"創建集成模型\"\"\"\n",
    "    print(\"創建集成模型...\")\n",
    "    \n",
    "    # 準備集成模型的估計器列表\n",
    "    ensemble_estimators = [\n",
    "        ('HybridModel', best_models['HybridModel']),\n",
    "    ]\n",
    "    \n",
    "    # 創建投票回歸器\n",
    "    ensemble_model = VotingRegressor(estimators=ensemble_estimators)\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"集成模型: {ensemble_model}\")\n",
    "    \n",
    "    return ensemble_model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train):\n",
    "    \"\"\"評估模型性能\"\"\"\n",
    "    print(\"評估模型性能...\")\n",
    "    \n",
    "    # 預測訓練集\n",
    "    train_predictions = model.predict(X_train)\n",
    "    \n",
    "    # 計算評估指標\n",
    "    mae = mean_absolute_error(y_train, train_predictions)\n",
    "    rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "    r2 = r2_score(y_train, train_predictions)\n",
    "    \n",
    "    print(f\"[訓練集] MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    return mae, rmse, r2\n",
    "\n",
    "def clip_outliers(train_df):\n",
    "    print(\"Clip 價格與連續特徵異常值...\")\n",
    "    \n",
    "    # clip price\n",
    "    q1, q3 = train_df['price'].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    train_df['price'] = train_df['price'].clip(upper=upper_bound)\n",
    "    \n",
    "    # Winsorize floorAreaSqM\n",
    "    fq1, fq3 = train_df['floorAreaSqM'].quantile([0.25, 0.75])\n",
    "    fiqr = fq3 - fq1\n",
    "    f_upper = fq3 + 1.5 * fiqr\n",
    "    train_df['floorAreaSqM'] = train_df['floorAreaSqM'].clip(upper=f_upper)\n",
    "    \n",
    "    return train_df\n",
    "def run_optuna_tuning(X_train, y_train, trend_features, machine_features, all_columns, n_trials=10):\n",
    "    \"\"\"使用 Optuna 進行超參數調優\"\"\"\n",
    "    print(\"開始 Optuna 超參數調優...\")\n",
    "    \n",
    "    # 創建 Optuna 研究\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    # 執行優化\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_train, y_train, trend_features, machine_features, all_columns),\n",
    "        n_trials=n_trials,show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    print(f\"最佳參數: {study.best_params}\")\n",
    "    print(f\"最佳 MAE: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 使用最佳參數創建最終模型\n",
    "    best_params = study.best_params\n",
    "    final_model = Pipeline([\n",
    "        ('Encoder', CustomEncoder()),\n",
    "        ('Model', HybridModel(\n",
    "            trend_model=Ridge(alpha=0.1),\n",
    "            machine_model=LGBMRegressor(device='gpu', **best_params),\n",
    "            trend_cols=trend_features,\n",
    "            machine_cols=machine_features,\n",
    "            all_columns=all_columns\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 訓練最終模型\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    return final_model\n",
    "\n",
    "def train_with_fixed_params(X_train, y_train, trend_features, machine_learning_features, best_params):\n",
    "    \"\"\"使用一組固定的超參數直接訓練最終模型\"\"\"\n",
    "    print(\"使用固定參數進行最終模型訓練...\")\n",
    "    print(f\"使用參數: {best_params}\")\n",
    "\n",
    "    # 創建包含 XGBoost 的模型管道\n",
    "    model_pipeline = Pipeline([\n",
    "        ('Encoder', CustomEncoder()),\n",
    "        ('Model', HybridModel(\n",
    "            trend_model=Ridge(), # alpha 將在下一步被設定\n",
    "            machine_model=XGBRegressor(random_state=42, eval_metric='mae'), # 其他參數將在下一步被設定\n",
    "            trend_cols=trend_features,\n",
    "            machine_cols=machine_learning_features,\n",
    "            all_columns=X_train.columns\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # 使用 set_params() 將您提供的參數應用到管道中\n",
    "    model_pipeline.set_params(**best_params)\n",
    "\n",
    "    # 訓練模型\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"模型訓練完成。\")\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T06:46:10.909807Z",
     "iopub.status.busy": "2025-06-19T06:46:10.909515Z",
     "iopub.status.idle": "2025-06-19T06:46:10.918779Z",
     "shell.execute_reply": "2025-06-19T06:46:10.918060Z",
     "shell.execute_reply.started": "2025-06-19T06:46:10.909774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"載入並準備訓練和測試資料\"\"\"\n",
    "    print(\"載入資料...\")\n",
    "    train_df = pd.read_csv('/kaggle/input/london-house-price/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/london-house-price/test.csv')\n",
    "    \n",
    "    # 為測試集添加空的價格欄位\n",
    "    test_df['price'] = np.nan\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def generate_submission(model, test_data):\n",
    "    \"\"\"生成提交檔案\"\"\"\n",
    "    print(\"生成提交檔案...\")\n",
    "    \n",
    "    # 載入提交模板\n",
    "    submission = pd.read_csv('/kaggle/input/london-house-price/sample_submission.csv')\n",
    "    \n",
    "    # 進行預測\n",
    "    test_features = test_data.drop('price', axis=1)\n",
    "    submission['price'] = model.predict(test_features)\n",
    "    \n",
    "    # 儲存提交檔案\n",
    "    submission.to_csv('submission_TimeSeriesSplit.csv', index=False)\n",
    "    print(\"提交檔案已儲存為 submission_TimeSeriesSplit.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:05:53.705608Z",
     "iopub.status.busy": "2025-06-19T11:05:53.704904Z",
     "iopub.status.idle": "2025-06-19T11:06:12.655132Z",
     "shell.execute_reply": "2025-06-19T11:06:12.654276Z",
     "shell.execute_reply.started": "2025-06-19T11:05:53.705587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 倫敦房價預測 - 混合模型 ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_and_prepare_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 執行主程序\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== 倫敦房價預測 - 混合模型 ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. 載入資料\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_df, test_df = \u001b[43mload_and_prepare_data\u001b[49m()\n\u001b[32m      7\u001b[39m data_list = [train_df, test_df]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. 創建時間特徵\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'load_and_prepare_data' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"主要執行流程\"\"\"\n",
    "    print(\"=== 倫敦房價預測 - 混合模型 ===\")\n",
    "    \n",
    "    # 1. 載入資料\n",
    "    train_df, test_df = load_and_prepare_data()\n",
    "    data_list = [train_df, test_df]\n",
    "    \n",
    "    # 2. 創建時間特徵\n",
    "    data_list = create_time_features(data_list)\n",
    "    \n",
    "    # 3. 設定時間索引\n",
    "    train_df = data_list[0].set_index('time')\n",
    "    test_df = data_list[1].set_index('time')\n",
    "    data_list = [train_df, test_df]\n",
    "    \n",
    "    # 4. 預處理地址特徵\n",
    "    data_list = preprocess_address_features(data_list)\n",
    "    \n",
    "    # 5. 處理缺失值\n",
    "    # data_list = handle_missing_values(data_list)\n",
    "    # train_df, test_df = data_list[0], data_list[1]\n",
    "    \n",
    "    # 5. 使用迭代式 LGBM 處理缺失值\n",
    "    train_df, test_df = handle_missing_values_lgbm([train_df, test_df])\n",
    "    \n",
    "    # 6. 創建時間序列特徵\n",
    "    train_df, test_df, time_series_features = create_time_series_features(train_df, test_df)\n",
    "    \n",
    "    # 7. 創建額外特徵\n",
    "    data_list = create_additional_features([train_df, test_df])\n",
    "    train_df, test_df = data_list[0], data_list[1]\n",
    "    \n",
    "    # Clip 房價 + Winsorize 特徵\n",
    "    # train_df = clip_outliers(train_df)\n",
    "    \n",
    "    # 8. 準備特徵\n",
    "    X_train, y_train, trend_features, machine_learning_features = prepare_features(\n",
    "        train_df, test_df, time_series_features\n",
    "    )\n",
    "    \n",
    "    # 9. 定義最佳參數並使用固定參數直接訓練模型\n",
    "    # 這組最佳是9\n",
    "    best_params = {\n",
    "        'Model__machine_model__learning_rate': 0.01,\n",
    "        'Model__machine_model__max_depth': 9,\n",
    "        'Model__machine_model__n_estimators': 500,\n",
    "        'Model__trend_model__alpha': 0.01\n",
    "    }\n",
    "    final_model = train_with_fixed_params(\n",
    "        X_train, y_train, trend_features, machine_learning_features, best_params\n",
    "    )\n",
    "\n",
    "    # 10. 評估模型\n",
    "    evaluate_model(final_model, X_train, y_train)\n",
    "    \n",
    "    # 11. 生成提交檔案\n",
    "    generate_submission(final_model, test_df)\n",
    "    \n",
    "    print(\"=== 程序執行完成 ===\")\n",
    "\n",
    "\n",
    "# 執行主程序\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7687677,
     "sourceId": 12204104,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7693306,
     "sourceId": 12212383,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dm_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
