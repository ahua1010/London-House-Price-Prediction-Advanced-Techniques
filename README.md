# 房價預測系統

## 專案概觀
本專案旨在開發一個基於機器學習的房價預測系統。透過分析歷史房產數據，建立一個包含特徵工程、模型訓練與預測的完整管線，核心目標是達到高準確度的預測能力。

## 技術棧
- **語言:** Python 3.8+
- **核心函式庫:**
  - `pandas`, `numpy`: 資料處理
  - `scikit-learn`: 機器學習工具
  - `xgboost`, `lightgbm`, `catboost`: 梯度提升模型
  - `joblib`, `pickle`: 模型序列化
  - `matplotlib`, `seaborn`: 資料視覺化

## 功能開發狀態追蹤表
| 功能或模組名稱 | 狀態 | 用途 | 核心功能 | 技術實現 | 用戶流程(導航) | 建議文件路徑 |
|---|---|---|---|---|---|---|
| 資料載入模組 | ✅ 已完成 | 從 CSV 檔案載入訓練與測試資料集。 | 讀取 `train.csv` 和 `test.csv`。 | 使用 `pandas.read_csv`。 | N/A (後端模組) | `src/data_loader.py` |
| 特徵工程模組 | ✅ 已完成 | 清理數據、處理缺失值、並從現有數據中創造新特徵以提升模型效能。 | 缺失值插補、時間/地理特徵生成、類別特徵編碼、自動化算術特徵組合。 | `impute_feature_with_lgbm`, `create_derived_features`, `process_categorical_features` | N/A (後端模組) | `src/feature_engineering.py` |
| 模型訓練與評估模組 | ✅ 已完成 | 訓練、評估並儲存機器學習模型。 | 使用時間序列交叉驗證進行模型堆疊 (Stacking)，包含特徵選擇、基礎模型訓練、元模型訓練及模型持久化。 | `run_time_series_stacking` 函式，使用 `TimeSeriesSplit`, `LightGBM` (特徵選擇), `XGBoost`, `CatBoost`, `ExtraTreesRegressor` (元模型)。 | N/A (後端模組) | `src/model_pipeline.py` |
| 預測管線模組 | ✅ 已完成 | 載入已訓練的模型，對新的測試資料進行預測，並產生提交檔案。 | 載入最新模型、應用特徵工程、執行堆疊預測、生成 submission.csv。 | `load_latest_model` 函式載入 `config.pkl`，`predict` 函式協調整個預測流程。 | N/A (後端模組) | `src/predict.py` |

## 技術實現細節

### 特徵工程模塊 詳細設計
此模組是提升模型預測能力的關鍵。它不只進行標準的數據清理，還採用了基於模型的先進技術來處理缺失值，並以高效能的方式自動探索新特徵。

- **LGBM 迭代式插補:** 對於 `floorAreaSqM`, `bedrooms`, `bathrooms` 等重要數值特徵的缺失值，並非使用簡單的中位數或均值填充。系統會進行多輪迭代，在每一輪中，獨立訓練 LightGBM 模型來預測缺失值。此方法利用了特徵間的相關性，能提供更精確的插補結果。
- **向量化特徵組合:** 為了發掘特徵間的深層關係，系統會自動探索特徵間的算術組合（加、減、乘、除）。**此過程經過了高度優化**：通過將 Pandas DataFrame 轉換為 NumPy 矩陣，利用向量化操作 (`np.dot`) 來進行高效的相關性計算，取代了原先緩慢的循環檢查，**將此步驟的性能提升了數個數量級**。系統會保留與目標相關性高且與現有特徵冗餘度低的新組合。
- **衍生特徵:** 創造了多種基於業務理解的衍生特徵，包括時間相關（如月份的正弦/餘弦轉換以捕捉週期性）、房產結構（如總房間數、房間面積比）和地理位置特徵。

### 模型訓練與評估模組 詳細設計
此模組採用了時間序列交叉驗證和模型堆疊（Stacking）兩種高級策略，並將特徵工程流程無縫整合，以確保模型的穩健性並根除數據洩漏。

- **防數據洩漏的交叉驗證流程:** 這是本專案流程設計的核心。為了防止數據洩漏，**所有的特徵工程和特徵選擇步驟都在交叉驗證的每一折 (Fold) 內部獨立執行**。具體流程如下：
  1.  在當前折，僅使用**訓練數據**來擬合 (`fit`) 所有預處理工具（如 `StandardScaler`、各種編碼器、LGBM插補模型）。
  2.  使用這些**已擬合**的工具去轉換 (`transform`) 當前折的**訓練數據**和**驗證數據**。
  3.  這個嚴格的隔離確保了模型在任何時刻都無法"看到"來自驗證集的資訊，從而使交叉驗證分數成為對模型真實性能的可靠評估。

- **模型堆疊 (Stacking):**
  1.  **基礎模型層:** 在交叉驗證的每一摺中，會訓練多個不同的基礎模型：
      - LightGBM (lgb)
      - XGBoost (xgb)
      - CatBoost (cat)
      - 線性回歸 (lr)
      - Ridge 回歸 (ridge)
  2.  **元特徵生成:** 將每個基礎模型對驗證集的預測結果（稱為 Out-of-Fold 預測）儲存起來，作為訓練元模型的「新特徵」。
  3.  **元模型層:** 使用四種不同的元模型策略：
      - 時間序列感知元模型：使用基模型預測值 + sale_year 作為特徵
      - 分層時間序列元模型：使用基模型預測值作為特徵
      - 時間序列交叉驗證元模型：使用基模型預測值作為特徵
      - 集成時間序列元模型：使用基模型預測值 + sale_year 作為特徵
     所有元模型都使用 ExtraTreesRegressor 作為基礎模型。

- **模型持久化:** 在所有交叉驗證完成後，系統會使用**全部訓練數據**重新訓練一次最終模型，並將所有必要的物件（包括特徵工程的最終配置、特徵列表、所有訓練好的模型）打包序列化到指定的 `output` 目錄中，方便預測管線直接調用。

## 測試案例摘要
目前專案未包含自動化測試案例。建議未來導入 `pytest` 以確保各模組功能的穩定性，特別是針對 `feature_engineering.py` 中的複雜轉換邏輯和 `model_pipeline.py` 的訓練流程。

## 系統架構
```
src/
├── data_processing/      # 數據處理模塊
├── feature_engineering/  # 特徵工程模塊
├── model_training/       # 模型訓練模塊
├── evaluation/          # 模型評估模塊
└── utils/              # 工具函數模塊
```

## 特徵工程模塊詳解 (v2.0 - 已重構)

本模塊遵循一個嚴格的、在交叉驗證內部執行的順序，以確保結果的穩健性和無洩漏性。

### 1. 執行流程概覽
`engineer_features` 函式是整個流程的總指揮，它嚴格按照以下順序調用各個子模塊：
1.  **分離目標變數**: 將 `price` 分離並進行 `log1p` 轉換，以應對數據偏態。
2.  **手動衍生特徵 (`create_derived_features`)**: 創造基於業務邏輯的特徵。
3.  **分類特徵處理 (`process_categorical_features`)**: 對 `object` 類型特徵進行編碼。
4.  **缺失值處理 (`handle_missing_values`)**: 使用模型進行迭代式插補。
5.  **自動化特徵組合 (`better_features`)**: **(性能已優化)** 自動發現新的交互特徵。
6.  **特徵縮放 (`scale_features`)**: 使用 `StandardScaler` 進行標準化。
7.  **特徵驗證 (`validate_features`)**: 最後的數據清理，處理極端值和殘留 `NaN`。
8.  **特徵選擇 (`select_features`)**: 使用多個樹模型（LGBM, XGBoost, CatBoost）投票選出最重要的特徵。

---

### 2. 各模塊細節

#### a. 手動衍生特徵
- **房間相關**:
  - `total_rooms`: 總房間數。
  - `rooms_per_area`: 單位面積的房間數。
  - `bathrooms_ratio`, `bedrooms_ratio`, `livingRooms_ratio`: 各類房間佔總房間數的比例。
- **地理位置相關**:
  - `lat_lon_ratio`, `lat_lon_product`: 經緯度的比值與乘積。
- **時間相關**:
  - `sin_month`, `cos_month`: 月份的週期性編碼。
  - `months_since_start`: 相對時間趨勢特徵。
  - `season`: 季節特徵。
- **缺失值指示器**:
  - 為 `bathrooms`, `bedrooms`, `floorAreaSqM` 等關鍵特徵創建 `_is_missing` 二元特徵。

#### b. 分類特徵處理
- **方法**: 採用**頻率編碼 (Frequency Encoding)**。
- **防洩漏**: 在每一折，頻率的計算**只基於**當前的訓練集數據。對於驗證集中出現的、訓練集未見過的新類別，會賦予一個預設的低頻率值。

#### c. 缺失值處理
- **策略**: 採用**迭代式 LGBM 模型插補**。
- **流程**: 對於多個有缺失的欄位，系統會進行 3 輪迭代。在每一輪中，輪流將一個欄位作為目標，用所有其他數值欄位作為特徵來訓練一個 LightGBM 模型，並用其預測填充該欄位的缺失值。

#### d. 自動化特徵組合 (核心優化點)
- **目標**: 遍歷所有數值特徵對，通過 `+`, `-`, `*`, `/` 創造候選特徵。
- **篩選標準**:
  1.  **有效性**: 與目標變數的相關性絕對值必須超過 `0.05`。
  2.  **獨立性**: 與所有現有特徵的相關性絕對值最高不能超過 `0.95`，以避免引入共線性。
- **性能優化**: 整個相關性計算過程已**完全向量化**。通過將數據轉換為 NumPy 陣列，利用 `np.dot` 進行矩陣運算，其速度遠超原先的循環 Pandas 實現。

#### e. 特徵選擇
- **策略**: 採用**模型投票法**。
- **流程**: 分別使用 `LightGBM`, `XGBoost`, `CatBoost` 三個模型來評估所有特徵的重要性，選出各自的 Top-K (預設為 40) 特徵。
- **最終結果**: 將三個模型選出的特徵集合併**取聯集**，作為最終進入模型訓練的特徵。如果特徵總數本身就少於 K，則跳過此步驟。

## 使用說明

### 環境要求
- Python 3.8+
- 相關依賴包（見 requirements.txt）

### 安裝步驟
1. 克隆專案
2. 安裝依賴：`pip install -r requirements.txt`
3. 配置環境變數

### 注意事項
1. **GPU 加速**：支援 XGBoost、LightGBM 和 CatBoost 的 GPU 訓練，大幅加快模型訓練速度。
2. **快速測試模式**：包含 `QUICK_TEST` 標誌，用於快速測試整個流程。啟用後，它將使用原始特徵的精簡子集和更少的交叉驗證次數（2 次而不是 5 次），以確保程式碼在完整執行時間的一小部分內無錯誤運行。

## 運行方法
1. **運行完整流程**：
執行主腳本以啟動訓練程序。這將運行完整的 5 倍時間序列交叉驗證。
```bash
python src/model_pipeline.py
```
訓練好的模型和最終的 `submission.csv` 將保存在 `output/` 目錄下帶有時間戳的子目錄中。

2. **執行快速測試**：
為了快速驗證整個流程是否正常運作（例如，在進行變更後），您可以啟用「QUICK_TEST」模式。強烈建議您在調試時使用此模式。
- 開啟"src/model_pipeline.py"。
- 將"QUICK_TEST = False"更改為"QUICK_TEST = True"。
- 按照上述方法運行腳本。這將使用較小的特徵集，並且僅進行兩輪交叉驗證，比完整運行更快完成。

## 注意事項
1. 確保數據文件放在正確的目錄
2. 檢查配置文件中的參數設置
3. 注意模型訓練的資源需求

## 未來計劃
1. 添加更多特徵工程方法
2. 優化模型性能
3. 增加模型解釋性分析
4. 開發 Web 界面

## 貢獻指南
歡迎提交 Pull Request 或提出 Issue。

## 授權說明
MIT License 